/home/gaoting/anaconda3/envs/tmp/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/home/gaoting/anaconda3/envs/tmp/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/home/gaoting/anaconda3/envs/tmp/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/home/gaoting/anaconda3/envs/tmp/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/home/gaoting/anaconda3/envs/tmp/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/home/gaoting/anaconda3/envs/tmp/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
/home/gaoting/anaconda3/envs/tmp/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/home/gaoting/anaconda3/envs/tmp/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/home/gaoting/anaconda3/envs/tmp/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/home/gaoting/anaconda3/envs/tmp/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/home/gaoting/anaconda3/envs/tmp/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/home/gaoting/anaconda3/envs/tmp/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
WARNING:tensorflow:From vae.py:19: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.

WARNING:tensorflow:From vae.py:100: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.

WARNING:tensorflow:From vae.py:102: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2020-12-19 17:50:52.889534: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2020-12-19 17:50:52.903842: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-12-19 17:50:52.904399: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:01:00.0
2020-12-19 17:50:52.904525: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.1
2020-12-19 17:50:52.905674: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10
2020-12-19 17:50:52.906715: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10
2020-12-19 17:50:52.906880: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10
2020-12-19 17:50:52.908024: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10
2020-12-19 17:50:52.908645: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10
2020-12-19 17:50:52.911122: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2020-12-19 17:50:52.911204: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-12-19 17:50:52.911782: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-12-19 17:50:52.912170: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2020-12-19 17:50:52.912349: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
2020-12-19 17:50:52.933755: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3699850000 Hz
2020-12-19 17:50:52.934237: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x563f27669c80 executing computations on platform Host. Devices:
2020-12-19 17:50:52.934284: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2020-12-19 17:50:52.934495: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-12-19 17:50:52.935053: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:01:00.0
2020-12-19 17:50:52.935084: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.1
2020-12-19 17:50:52.935095: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10
2020-12-19 17:50:52.935106: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10
2020-12-19 17:50:52.935116: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10
2020-12-19 17:50:52.935127: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10
2020-12-19 17:50:52.935137: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10
2020-12-19 17:50:52.935153: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2020-12-19 17:50:52.935192: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-12-19 17:50:52.935778: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-12-19 17:50:52.936167: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2020-12-19 17:50:52.936188: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.1
2020-12-19 17:50:53.058402: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-12-19 17:50:53.058428: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 
2020-12-19 17:50:53.058434: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N 
2020-12-19 17:50:53.058563: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-12-19 17:50:53.058928: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-12-19 17:50:53.059268: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-12-19 17:50:53.059587: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10249 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)
2020-12-19 17:50:53.060721: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x563f28d1b830 executing computations on platform CUDA. Devices:
2020-12-19 17:50:53.060732: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): GeForce GTX 1080 Ti, Compute Capability 6.1
WARNING:tensorflow:From ../target_lstm.py:21: The name tf.set_random_seed is deprecated. Please use tf.compat.v1.set_random_seed instead.

WARNING:tensorflow:From ../target_lstm.py:23: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.

WARNING:tensorflow:From ../target_lstm.py:52: multinomial (from tensorflow.python.ops.random_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.random.categorical` instead.
WARNING:tensorflow:From ../target_lstm.py:97: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.cast` instead.
WARNING:tensorflow:From ../common/lstm_utils.py:45: MultiRNNCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.
Instructions for updating:
This class is equivalent as tf.keras.layers.StackedRNNCells, and will be replaced by that in Tensorflow 2.0.
WARNING:tensorflow:From /home/gaoting/anaconda3/envs/tmp/lib/python3.7/site-packages/tensorflow/contrib/rnn/python/ops/rnn.py:239: bidirectional_dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.
Instructions for updating:
Please use `keras.layers.Bidirectional(keras.layers.RNN(cell))`, which is equivalent to this API
WARNING:tensorflow:From /home/gaoting/anaconda3/envs/tmp/lib/python3.7/site-packages/tensorflow/python/ops/rnn.py:464: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.
Instructions for updating:
Please use `keras.layers.RNN(cell)`, which is equivalent to this API
WARNING:tensorflow:From /home/gaoting/anaconda3/envs/tmp/lib/python3.7/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
WARNING:tensorflow:From /home/gaoting/anaconda3/envs/tmp/lib/python3.7/site-packages/tensorflow/contrib/rnn/python/ops/core_rnn_cell.py:104: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
WARNING:tensorflow:From /home/gaoting/anaconda3/envs/tmp/lib/python3.7/site-packages/tensorflow/python/ops/rnn.py:244: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.where in 2.0, which has the same broadcast rule as np.where
WARNING:tensorflow:From ../seq_vae_1/encoder.py:65: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.
Instructions for updating:
Use keras.layers.dense instead.
WARNING:tensorflow:From ../seq_vae_1/encoder.py:99: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.

2020-12-19 17:50:56.508667: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10
2020-12-19 17:50:57.230703: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
#########################################################################
Start Training...
epoch  0 kl_loss:  0.79031587 r_loss:  7.765085 nll:  9.796799
epoch  5 kl_loss:  0.34440985 r_loss:  6.835626 nll:  9.024365
epoch  10 kl_loss:  0.016685937 r_loss:  6.4546924 nll:  8.916148
epoch  15 kl_loss:  0.021019889 r_loss:  6.264933 nll:  8.868068
epoch  20 kl_loss:  0.015536094 r_loss:  6.1536245 nll:  8.827761
epoch  25 kl_loss:  0.027051624 r_loss:  6.0912023 nll:  8.817273
epoch  30 kl_loss:  0.01790095 r_loss:  6.042833 nll:  8.812229
epoch  35 kl_loss:  0.054379463 r_loss:  6.0102 nll:  8.811497
epoch  40 kl_loss:  0.02246403 r_loss:  5.985044 nll:  8.798365
epoch  45 kl_loss:  0.03198062 r_loss:  5.9696503 nll:  8.793476
epoch  50 kl_loss:  0.018598886 r_loss:  5.9641066 nll:  8.810728
epoch  55 kl_loss:  0.023080703 r_loss:  5.9496994 nll:  8.804506
epoch  60 kl_loss:  0.038112234 r_loss:  5.9492955 nll:  8.808883
epoch  65 kl_loss:  0.009467118 r_loss:  5.9348702 nll:  8.810432
epoch  70 kl_loss:  0.04358569 r_loss:  5.9413505 nll:  8.804814
epoch  75 kl_loss:  0.024424262 r_loss:  5.9301844 nll:  8.793368
epoch  80 kl_loss:  0.008613773 r_loss:  5.928164 nll:  8.806983
epoch  85 kl_loss:  0.013594343 r_loss:  5.9303536 nll:  8.812295
epoch  90 kl_loss:  0.027070474 r_loss:  5.9285607 nll:  8.801756
epoch  95 kl_loss:  0.022228127 r_loss:  5.9333096 nll:  8.808675
epoch  100 kl_loss:  0.032594055 r_loss:  5.931711 nll:  8.816395
epoch  105 kl_loss:  0.010657534 r_loss:  5.9361434 nll:  8.7962475
epoch  110 kl_loss:  0.017910523 r_loss:  5.9384513 nll:  8.8251505
epoch  115 kl_loss:  0.0037460334 r_loss:  5.939042 nll:  8.809594
epoch  120 kl_loss:  0.008451766 r_loss:  5.943252 nll:  8.816268
epoch  125 kl_loss:  0.03475227 r_loss:  5.9531393 nll:  8.817923
epoch  130 kl_loss:  0.02967164 r_loss:  5.9498215 nll:  8.81933
epoch  135 kl_loss:  0.00483585 r_loss:  5.9518228 nll:  8.832873
epoch  140 kl_loss:  0.014815404 r_loss:  5.949601 nll:  8.820916
epoch  145 kl_loss:  0.02595221 r_loss:  5.9600143 nll:  8.823356
epoch  150 kl_loss:  0.01296772 r_loss:  5.958305 nll:  8.831428
epoch  155 kl_loss:  0.004060787 r_loss:  5.9634976 nll:  8.811047
epoch  160 kl_loss:  0.07275145 r_loss:  5.9717875 nll:  8.831789
epoch  165 kl_loss:  0.024970595 r_loss:  5.9690204 nll:  8.834627
epoch  170 kl_loss:  0.0038169469 r_loss:  5.9937367 nll:  8.837328
epoch  175 kl_loss:  0.014038217 r_loss:  5.986277 nll:  8.828574
epoch  180 kl_loss:  0.0074087656 r_loss:  5.9835835 nll:  8.820159
epoch  185 kl_loss:  0.10199144 r_loss:  5.9914083 nll:  8.850571
epoch  190 kl_loss:  0.00410171 r_loss:  5.9894886 nll:  8.839335
epoch  195 kl_loss:  0.0133758085 r_loss:  5.9890795 nll:  8.835639
epoch  200 kl_loss:  0.036991443 r_loss:  5.9970837 nll:  8.838818
epoch  205 kl_loss:  0.021355797 r_loss:  5.998314 nll:  8.841782
epoch  210 kl_loss:  0.004280947 r_loss:  6.001255 nll:  8.8478985
epoch  215 kl_loss:  0.0084322365 r_loss:  6.0060654 nll:  8.830502
epoch  220 kl_loss:  0.028791599 r_loss:  6.009358 nll:  8.832299
epoch  225 kl_loss:  0.008237158 r_loss:  6.027152 nll:  8.835903
epoch  230 kl_loss:  0.03759692 r_loss:  6.0208983 nll:  8.857873
epoch  235 kl_loss:  0.008878005 r_loss:  6.0180235 nll:  8.843939
epoch  240 kl_loss:  0.029942675 r_loss:  6.0311046 nll:  8.843818
epoch  245 kl_loss:  0.01969027 r_loss:  6.034096 nll:  8.844684
epoch  250 kl_loss:  0.017113922 r_loss:  6.0522957 nll:  8.856899
epoch  255 kl_loss:  0.016534701 r_loss:  6.0493984 nll:  8.8681135
epoch  260 kl_loss:  0.047137633 r_loss:  6.065823 nll:  8.867284
epoch  265 kl_loss:  0.031043505 r_loss:  6.063816 nll:  8.852549
epoch  270 kl_loss:  0.018324671 r_loss:  6.0581174 nll:  8.862333
epoch  275 kl_loss:  0.009445892 r_loss:  6.0601654 nll:  8.855532
epoch  280 kl_loss:  0.011015508 r_loss:  6.0828614 nll:  8.874417
epoch  285 kl_loss:  0.011361882 r_loss:  6.0737147 nll:  8.862885
epoch  290 kl_loss:  0.010396857 r_loss:  6.0715265 nll:  8.860646
epoch  295 kl_loss:  0.019915204 r_loss:  6.0816565 nll:  8.876058
epoch  300 kl_loss:  0.036567565 r_loss:  6.0940804 nll:  8.872853
epoch  305 kl_loss:  0.010256922 r_loss:  6.0892954 nll:  8.8672695
epoch  310 kl_loss:  0.010154211 r_loss:  6.091693 nll:  8.866043
epoch  315 kl_loss:  0.015723214 r_loss:  6.0910015 nll:  8.86508
epoch  320 kl_loss:  0.012826241 r_loss:  6.102783 nll:  8.865563
epoch  325 kl_loss:  0.094962865 r_loss:  6.0918727 nll:  8.881202
epoch  330 kl_loss:  0.026585102 r_loss:  6.1027513 nll:  8.873594
epoch  335 kl_loss:  0.006684898 r_loss:  6.1045885 nll:  8.871409
epoch  340 kl_loss:  0.0053347466 r_loss:  6.1000047 nll:  8.869942
epoch  345 kl_loss:  0.016259233 r_loss:  6.1001077 nll:  8.878499
epoch  350 kl_loss:  0.013061227 r_loss:  6.1180353 nll:  8.871292
epoch  355 kl_loss:  0.0020590466 r_loss:  6.115519 nll:  8.893924
epoch  360 kl_loss:  0.003914623 r_loss:  6.0997744 nll:  8.879537
epoch  365 kl_loss:  0.009022411 r_loss:  6.1312723 nll:  8.890925
epoch  370 kl_loss:  0.03642275 r_loss:  6.136318 nll:  8.886717
epoch  375 kl_loss:  0.0062060356 r_loss:  6.121315 nll:  8.876923
epoch  380 kl_loss:  0.030885782 r_loss:  6.114619 nll:  8.892107
epoch  385 kl_loss:  0.042308416 r_loss:  6.124651 nll:  8.87944
epoch  390 kl_loss:  0.011386376 r_loss:  6.1229343 nll:  8.888064
epoch  395 kl_loss:  0.014360755 r_loss:  6.1275115 nll:  8.878787
